{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c45903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DEVELOPER_KEY = \"AIzaSyAYvRpVKJUS5MUnw6NVcIQB484ao6CdutE\" #from YouTube API\n",
    "\n",
    "from my_functions import ident_lang, files_in_dir, save_to_cache, video_class\n",
    "\n",
    "#standart packages\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from tqdm.notebook import tqdm\n",
    "#tqdm.pandas()\n",
    "#$ pip install ipywidgets widgetsnbextension pandas-profiling\n",
    "#$ jupyter nbextension enable --py widgetsnbextension\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "#language detection\n",
    "from langdetect import detect\n",
    "\n",
    "#comment download\n",
    "import os\n",
    "import googleapiclient\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_class.instances = []\n",
    "\n",
    "# title, artist, year, video_id, status, genre\n",
    "## video_id = id from video URL\n",
    "## status = schnulze/nicht-schnulze\n",
    "## genre = optional\n",
    "\n",
    "#my_video = video_class(title, artist, year, video_id, status, genre)\n",
    "\n",
    "sheeran_video = video_class('Thinking_Out_Loud', 'Ed_Sheeran', 2014, 'lp-EO5I60KA', 1, 'Pop')\n",
    "clarkson_video = video_class('Because_Of_You', 'Kelly_Clarkson', 2005, 'Ra-Om7UMSJc', 1, 'Pop')\n",
    "legend_video = video_class('All_of_Me', 'John_Legend', 2013, '450p7goxZqg', 1, 'Pop')\n",
    "odell_video = video_class('Another_Love', 'Tom_Odell', 2012, 'MwpMEbgC7DA', 1, 'Pop')\n",
    "\n",
    "mars_video = video_class('When_I_Was_Your_Man', 'Bruno_Mars', 2013, 'ekzHIouo8Q4', 1, 'Pop')\n",
    "helena_video = video_class('My_Chemical_Romance', 'Helena', 2004, 'UCCyoocDxBA', 1, 'punk rock')\n",
    "sixpence_video = video_class('Kiss_Me', 'Sixpence_None_The_Richer', 1997, 'Jnq9wPDoDKg', 1, 'pop')\n",
    "nirvana_video = video_class('Where_did_you_sleep_last_night', 'Nirvana', 1994, 'hEMm7gxBYSc', 1, 'rock')\n",
    "weeknd_video = video_class('Out_of_Time', 'The_Weeknd', 2022, '2fDzCWNS3ig', 1, 'pop')\n",
    "ladygaga_video = video_class('Hold_My_Hand', 'Lady_Gaga', 2022, 'O2CIAKVTOrc', 1, 'pop')\n",
    "\n",
    "abba_video = video_class('The_Winner_Takes_It_All', 'Abba', 0, '8tE0GjSQpes', 1, 'pop')\n",
    "\n",
    "\n",
    "print(*video_class.instances, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DOWNLOAD COMMENTS ###\n",
    "'''\n",
    "Get {len_output} Comments of Video \"{video_class_object}\", in order of {order}\n",
    "\n",
    "downloads are saved as DataFrame of ('author', 'comment', 'origin', 'origin_status')\n",
    "and in data/download_cache/\n",
    "'''\n",
    "\n",
    "#ladygaga_video_com = ladygaga_video.get_comments(DEVELOPER_KEY, len_output=500000, order=\"time\")\n",
    "#save_to_cache(ladygaga_video_com)\n",
    "#save_to_cache(sheeran_video.get_comments(DEVELOPER_KEY, len_output=500000, order=\"time\"))\n",
    "#save_to_cache(clarkson_video.get_comments(DEVELOPER_KEY, len_output=500000, order=\"time\"))\n",
    "#save_to_cache(legend_video.get_comments(DEVELOPER_KEY, len_output=500000, order=\"time\"))\n",
    "#save_to_cache(odell_video.get_comments(DEVELOPER_KEY, len_output=500000, order=\"time\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a413cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print what is in download_cache\n",
    "print(*files_in_dir(\"data/download_cache/\"), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_of_output = \"combined_data\"\n",
    "'''\n",
    "This cell combines data (if wanted)\n",
    "and saves it under data/combined\n",
    "\n",
    "'''\n",
    "\n",
    "df1 = pd.read_pickle(\"data/download_cache/Ed_Sheeran-Thinking_Out_Loud-280373.pkl\")\n",
    "df2 = pd.read_pickle(\"data/download_cache/Bruno_Mars-When_I_Was_Your_Man_155312.pkl\")\n",
    "df3 = pd.read_pickle(\"data/download_cache/John_Legend-All_of_Me-187985.pkl\")\n",
    "df4 = pd.read_pickle(\"data/download_cache/Tom_Odell-Another_Love-90400.pkl\")\n",
    "\n",
    "data_combined = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "print(data_combined.shape)\n",
    "data_combined.to_pickle(\"data/combined/{}.pkl\".format(filename_of_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6600d",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a31870",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print what is in download_cache\n",
    "files_in_dir(\"data/download_cache/\")\n",
    "\n",
    "### print what is in data/combined\n",
    "files_in_dir(\"data/combined/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85db266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(714070, 5)\n",
      "deleted extreamly long comments (which are probably lyrics)\n",
      "(709027, 5)\n",
      "deleted all comments without latin characters\n",
      "(647435, 5)\n",
      "language detection - this can take some time\n",
      "1 von 647435\n",
      "Xxxxxxxxxxx❣️❣️❣️❣️❣️❣️❣️❣️😋😋😋😋😋💞💞💞💞\n",
      "https://youtu.be/vYbbhlpqwMk\n",
      "https://www.youtube.com/watch?v=tGRzz0oqgUE\n",
      "https://www.youtube.com/watch?v=8jCFzreP1ng\n",
      "https://www.youtube.com/watch?v=gD6cPE2BHic\n",
      "https://www.youtube.com/watch?v=nZtdcMIR5do\n",
      "https://www.youtube.com/watch?v=R4id7iOkom8\n",
      "https://youtu.be/7ipxue9UC-M\n",
      "https://youtu.be/oIphuKnmWMo\n",
      "https://www.youtube.com/watch?v=FkggUSTVqGg&list=RDPdOyCxLa83Y&index=4\n",
      "❤❤❤❤❤❤❤❤ooo\n",
      "Lindos ❤👏🏻👏🏻👏🏻👏🏻👏🏻👏🏻👏🏻👏🏻👏🏻❤\n",
      "https://youtu.be/bly09DMJ22M\n",
      "https://youtu.be/sRgA9jy_DOM\n",
      "\n",
      "CopyCat E.S!! Marvin Gaye RIP!!!💕🙏💯💯👍👏👏💓💓🔥❤️❤️🎉🎉✨👌👌😍😍🙌💕🙏💯💯👍👏💓💓❤️🎉✨👌😍😍💕💯👍💓💓🔥✨👌😍\n",
      "https://youtu.be/WyEYEgRN8Mc\n",
      "https://www.youtube.com/watch?v=CoOXbP7hmc0\n",
      "\n",
      "https://www.youtube.com/watch?v=x6QZn9xiuOE\n",
      "\n",
      "\n",
      "https://youtu.be/RMZMeMj9oDE\n",
      "https://youtu.be/GYKURLUCl8o\n",
      "https://youtu.be/elZzRMNa_q4\n",
      "\n",
      "🤠🌵 https://youtu.be/U9Rqa7dc8hs\n",
      "https://youtu.be/A8orgok_bcc\n",
      "https://youtu.be/QP0wQ0CQG0Q\n",
      "😠😠😠😠😠😠😠😠😠😠😠😠😠😠🤔😠🤔😠🤔😠🤔😠😡😡😡😡😡😡😡😡😡😡😡😡😡😡😡👍7.4.2023 EDD SHANEN ETC\n",
      "https://youtu.be/fRSSsm1GsNw\n",
      "I'm the one❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😅😅😅😅😅😅😅😅😅😅😅😅😅😅😅🎉🎉🎉🎉🎉🎉🎉🎉🎉❤❤❤❤❤❤❤❤\n",
      "I love this🎉😢😂😢😢🎉😂❤❤❤❤❤❤❤❤❤❤❤❤❤❤❤\n",
      "https://youtu.be/0bKqXurShmM\n",
      "https://youtu.be/BGN2oTjnA_M\n",
      "5000 von 647435\n",
      "https://youtu.be/5_boVpChmMA\n",
      "https://youtu.be/-oLaq3cQwFQ 🔥🔥🔥🔥🔥🔥🔥🔥🔥\n",
      "https://www.youtube.com/watch?v=W-Vd-qQQZd8&t=16s\n",
      "https://youtu.be/ONS5gJN4ZUw\n",
      "https://youtu.be/65g18NQv2po\n",
      "https://youtu.be/5QtBGyveFpo\n",
      "https://youtube.com/shorts/9tGkC86Svqo?feature=share\n",
      "❤️😍S.M😍❤️\n",
      "https://youtu.be/Zq2mFqnszyA\n",
      "https://youtu.be/LunF-YDc30Q\n",
      "https://youtube.com/shorts/mLtS79YNahM?feature=share\n",
      "Hey 💞🙌🏼💞💞🙌🏼💞🙌🏼💞😏\n",
      "https://youtube.com/shorts/IBJkDWfaafo?feature=share\n",
      "Wow!⬆️🌬️⬆️🙏⬆️🕯️🌌\n",
      "https://youtu.be/qRzc1o0XwJw\n",
      "https://youtu.be/8xg3vE8Ie_E\n",
      "https://youtu.be/VuNIsY6JdUw\n",
      "https://youtu.be/jqgPC9guiv8\n",
      "https://youtu.be/OblL026SvD4\n",
      "https://youtu.be/HDoeOWYGbBE\n",
      "https://www.youtube.com/channel/UCROrgHfOXQ8uI4W-0gFTbUg\n",
      "https://youtu.be/F9f-dUa2hMw\n",
      "Show!!!!!!!💯💯💯💯💯👋👋👋👋👋👋👋👋👋👋👋👍👍👍👍👍👍👍👍👍👍👍👋👋👋👋👋👋👋👋👋👋👋👋\n",
      "https://m.youtube.com/watch?v=DwK9P_a-OA8\n",
      "Beautiful ❤️🥰🥰❤️🥰🥰❤️🥰🥰❤️🥰🥰❤️🥰🥰❤️🥰🥰\n",
      "https://youtu.be/RP9N8josxbg\n",
      "ya  so  right ♥️♥️♥️♥️♥️♥️♥️♥️♥️♥️♥️\n",
      "❤️\n",
      "https://youtube.com/watch?v=28lOMzhNdAg&si=EnSIkaIECMiOmarE\n",
      "https://youtu.be/syG_fCNPSTQ\n",
      "https://youtube.com/shorts/BihslTz_-EE?feature=share\n",
      "OMG!!!!! 😍😍😍😍😍😍😍😍\n",
      "6yu76yyyuuuyyuyuu😆😆😆😆😆🤩🤩🤩😍😍🥰🥰🥰😶‍🌫️😶‍🌫️😶‍🌫️😶‍🌫️\n",
      "https://youtu.be/F9f-dUa2hMw\n",
      "https://youtu.be/18foq__Yut0\n",
      "TEMAZO!!!!💃🕺🪄✨️✨️✨️✨️✨️🙏🌇\n",
      "https://www.youtube.com/watch?v=r3j6XdubOqE\n",
      "https://www.youtube.com/watch?v=jns6Ck0Ce4g\n",
      "i love this song🥰🥰🥰🥰😍😍😍😍😍🤩🤩🤩🤩😘😘😘😘🤤🤤🤤🤤🤤🤤🤢❣️❤️💌💓💗💞💕👩‍❤️‍💋‍👨🌷🌸🌺🌹⭐🌟🏅🎖️🥇💌❤️♥️\n",
      "https://www.youtube.com/watch?v=l7dQCSdYNuI\n",
      "https://youtu.be/SIvYg3K9YMU\n",
      "\n",
      "https://youtube.com/channel/UCB9xEKndDv_ZMRpjuSxpMZA\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m df_comments \u001b[38;5;241m=\u001b[39m df_comments\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m## initiate detection\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m df_comments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_comments\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mident_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# print\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename_of_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     51\u001b[0m df_comments \u001b[38;5;241m=\u001b[39m df_comments\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m## initiate detection\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m df_comments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_comments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mident_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# print\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename_of_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Heavy_Projects/GitHub/yt_schnulzen/my_functions/language_ident.py:13\u001b[0m, in \u001b[0;36mident_lang\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mident_lang\u001b[39m(x):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m         language \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m LangDetectException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/langdetect/detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/langdetect/detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/langdetect/detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/langdetect/detector.py:161\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_lang_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mngrams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_prob(prob) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONV_THRESHOLD \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mITERATION_LIMIT:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/my_ml_env2/lib/python3.10/site-packages/langdetect/detector.py:212\u001b[0m, in \u001b[0;36mDetector._update_lang_prob\u001b[0;34m(self, prob, word, alpha)\u001b[0m\n\u001b[1;32m    210\u001b[0m weight \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBASE_FREQ\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m xrange(\u001b[38;5;28mlen\u001b[39m(prob)):\n\u001b[0;32m--> 212\u001b[0m     prob[i] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m weight \u001b[38;5;241m+\u001b[39m lang_prob_map[i]\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import swifter\n",
    "import pandas as pd\n",
    "from my_functions import ident_lang\n",
    "#import PySimpleGUI as sg\n",
    "\n",
    "\n",
    "\n",
    "#load data\n",
    "df_comments = pd.read_pickle(\"data/combined/combined_data.pkl\")\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "print(df_comments.shape)\n",
    "\n",
    "#output filename\n",
    "filename_of_output = \"processed_data\"\n",
    "\n",
    "'''\n",
    "The following cell takes an Dataframe and:\n",
    "- Deletes very long comments\n",
    "- tidys and deletes all empty comments\n",
    "- deletes all non-english comments\n",
    "\n",
    "It also saves the resulting Dataframe under data/processed\n",
    "'''\n",
    "\n",
    "### Pre Process\n",
    "\n",
    "print(\"deleted extreamly long comments (which are probably lyrics)\")\n",
    "df_comments = df_comments[df_comments['comment'].str.len()<1100] #aprox 200 words\n",
    "print(df_comments.shape)\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "\n",
    "\n",
    "## deleted all comments without latin characters\n",
    "print(\"deleted all comments without latin characters\")\n",
    "#find rows\n",
    "patternDel = fr\"^\\A[^a-z]+\\Z\"\n",
    "i_filter = df_comments['comment'].str.contains(patternDel, regex=True, case=False)\n",
    "#keep all rows which indices do not match i_filter\n",
    "df_comments = df_comments[~i_filter]\n",
    "print(df_comments.shape)\n",
    "\n",
    "## deleted all comments which are only URL\n",
    "print(\"deleted all comments which are only URL\")\n",
    "#find rows\n",
    "patternDel = fr\"^\\Ahttps?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\\Z\"\n",
    "i_filter = df_comments['comment'].str.contains(patternDel, regex=True, case=False)\n",
    "#keep all rows which indices do not match i_filter\n",
    "df_comments = df_comments[~i_filter]\n",
    "print(df_comments.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"language detection - this can take some time\")\n",
    "## to show progress\n",
    "ident_lang.index = 0\n",
    "ident_lang.length = df_comments.shape[0]\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "\n",
    "## initiate detection\n",
    "df_comments[\"lang\"] = df_comments[\"comment\"].apply(lambda x: ident_lang(x))\n",
    "\n",
    "\n",
    "# print\n",
    "print(f\"file saved as {filename_of_output}\")\n",
    "#save\n",
    "#df_comments.to_pickle(\"data/processed/{}.pkl\".format(filename_of_output))\n",
    "\n",
    "#print(df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c24430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea403e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309d682e",
   "metadata": {},
   "source": [
    "# Analyse Time Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816229e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print what is in processed\n",
    "files_in_dir(\"data/processed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf48b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ts(comment : str):\n",
    "    print(comment)\n",
    "    \n",
    "\n",
    "#load\n",
    "#df_comments = pd.read_csv(\"data/download_data_combined_tidy.tsv\", sep=\"\\t\")\n",
    "df_comments = pd.read_csv(\"comment_downloads/data_combined_53221_V2.tsv\", sep=\"\\t\")\n",
    "df_comments.dropna(how='all')\n",
    "\n",
    "#extract TSs\n",
    "df_comments['time_stamp'] = df_comments.head(100).apply(lambda x: extract_ts(x, video_min), axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8202e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_ml_env2)",
   "language": "python",
   "name": "my_ml_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
