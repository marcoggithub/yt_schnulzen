{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00011be",
   "metadata": {},
   "source": [
    "# Skript zum Download von YouTube-Kommentaren und Analyse der time stamps in diesen Kommentare\n",
    "von Q. Bukold & M. Gronewold - 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11775ad",
   "metadata": {},
   "source": [
    "User können auf YouTube in ihren Kommentaren mit Hilfe der Syntax „MM:SS“ einfach auf einen bestimmten Zeitpunkt im Video aufmerksam machen bzw. sich darauf beziehen. Unser Untersuchungsgegenstand sind jene time stamps und schnulzige Musikvideos. \n",
    "\n",
    "Ziel der Datenerhebung durch dieses Skript ist zu prüfen, ob Kommentare die time stamps enthalten besonders dem Schnulzigen zuzuschreiben sind und ob jene Kommentare einen besonders schnulzigen Moment im Video referieren. Dafür sollen quantitative und qualitative Methoden zum Einsatz kommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Welcome to this script. Please run this cell to create all Directories needed and import all packages.\n",
    "\n",
    "'''\n",
    "# Jupyter Config\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# standard packages\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# specific packages\n",
    "import googleapiclient\n",
    "from googleapiclient.discovery import build\n",
    "from langdetect import detect\n",
    "\n",
    "# optional packages\n",
    "import tabloo # tabloo.show(df) nicely displays your DataFrames\n",
    "\n",
    "# import own functions\n",
    "from my_functions import ident_lang, files_in_dir, save_to_cache, video_class, extract_ts\n",
    "\n",
    "# create all needed directories\n",
    "data_dir0 = \"data\"\n",
    "data_dir1 = \"data/1-download_cache\"\n",
    "data_dir2 = \"data/2-combined_data\"\n",
    "data_dir3 = \"data/3-processed_data\"\n",
    "data_dir4 = \"data/3-processed_data/cache\"\n",
    "\n",
    "figures_dir = \"figures/\"\n",
    "model_dir = \"bert/models/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(data_dir0):\n",
    "    os.mkdir(data_dir0)\n",
    "if not os.path.exists(data_dir1):\n",
    "    os.mkdir(data_dir1)\n",
    "if not os.path.exists(data_dir2):\n",
    "    os.mkdir(data_dir2)\n",
    "if not os.path.exists(data_dir3):\n",
    "    os.mkdir(data_dir3)\n",
    "if not os.path.exists(data_dir4):\n",
    "    os.mkdir(data_dir4)\n",
    "\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.mkdir(figures_dir)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b93e34",
   "metadata": {},
   "source": [
    "## Festlegung der Videos\n",
    "In der folgenden Zelle lassen sich aus den benötigten Metadaten des Videos ein Video-Objekt erstellen. Dieses ist frei bennenbar und wird benötigt, um in der darauffolgenden Zelle die Kommentare herunterzuladen.\n",
    "\n",
    "```\n",
    "Please use the video_class(title, artist, year, video_id, status, genre) function to create an Video Object\n",
    "for downloading.\n",
    "\n",
    "## video_id = id from video URL\n",
    "## status = schnulze/nicht-schnulze\n",
    "## genre = optional\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import video_class\n",
    "\n",
    "video_class.instances = []\n",
    "\n",
    "sheeran_video = video_class(title = 'Thinking_Out_Loud',\n",
    "                            artist = 'Ed_Sheeran',\n",
    "                            year = 2014,\n",
    "                            video_id = 'lp-EO5I60KA',\n",
    "                            status = 1,\n",
    "                            genre = 'Pop')\n",
    "\n",
    "clarkson_video = video_class('Because_Of_You', 'Kelly_Clarkson', 2005, 'Ra-Om7UMSJc', 1, 'Pop')\n",
    "legend_video = video_class('All_of_Me', 'John_Legend', 2013, '450p7goxZqg', 1, 'Pop')\n",
    "odell_video = video_class('Another_Love', 'Tom_Odell', 2012, 'MwpMEbgC7DA', 1, 'Pop')\n",
    "mars_video = video_class('When_I_Was_Your_Man', 'Bruno_Mars', 2013, 'ekzHIouo8Q4', 1, 'Pop')\n",
    "helena_video = video_class('My_Chemical_Romance', 'Helena', 2004, 'UCCyoocDxBA', 1, 'punk rock')\n",
    "sixpence_video = video_class('Kiss_Me', 'Sixpence_None_The_Richer', 1997, 'Jnq9wPDoDKg', 1, 'pop')\n",
    "nirvana_video = video_class('Where_did_you_sleep_last_night', 'Nirvana', 1994, 'hEMm7gxBYSc', 1, 'rock')\n",
    "weeknd_video = video_class('Out_of_Time', 'The_Weeknd', 2022, '2fDzCWNS3ig', 1, 'pop')\n",
    "ladygaga_video = video_class('Hold_My_Hand', 'Lady_Gaga', 2022, 'O2CIAKVTOrc', 1, 'pop')\n",
    "abba_video = video_class('The_Winner_Takes_It_All', 'Abba', 0, '8tE0GjSQpes', 1, 'pop')\n",
    "\n",
    "\n",
    "#print(*video_class.instances, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b3627",
   "metadata": {},
   "source": [
    "## Download der Video-Kommentare\n",
    "Nun lassen sich die Objektnamen benutzen, um beliebig viele Kommentare herunterzuladen.\\\n",
    "Dabei sollte die folgende Syntax benutzt werden:\n",
    "- save_to_cache(objektname.get_comments(DEVELOPER_KEY, len_output=NUMMER, order=\"time\"/\"relevance\"))\n",
    "- Der Developer Key muss bei Google beantragt werden\n",
    "\n",
    "-------\n",
    "\n",
    "```\n",
    "### DOWNLOAD COMMENTS ###\n",
    "Please use the save_to_cache(video_object.get_comments(dev_key : str, len_output : int, order : str)) command\n",
    "dev_key = Developer Key provided by YouTube for API usage\n",
    "len_output = max. amount of comments wanted from that video\n",
    "order = can be set to \"time\" or \"relevance\". The relevance of a Comment is computed by YouTube,\n",
    "time downloads the newest comments\n",
    "\n",
    "example:\n",
    "#save_to_cache(sheeran_video.get_comments(DEVELOPER_KEY, len_output=500000, order=\"time\"))\n",
    "\n",
    "=> downloads are saved as DataFrame with columns = ('author', 'comment', 'origin', 'origin_status')\n",
    "in folder data/1-download_cache\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8eebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment download\n",
    "import os\n",
    "import googleapiclient\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from my_functions import save_to_cache, video_class\n",
    "DEVELOPER_KEY = \"AIzaSyAYvRpVKJUS5MUnw6NVcIQB484ao6CdutE\" #for YouTube API\n",
    "\n",
    "\n",
    "save_to_cache(sheeran_video.get_comments(DEVELOPER_KEY, len_output=500, order=\"time\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0540a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print filennames of download_cache-files ###\n",
    "print(*files_in_dir(\"data/1-download_cache\"), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b79e74",
   "metadata": {},
   "source": [
    "### Kombination von Downloads\n",
    "Mit der folgenden Zelle lassen sich einzelne downloads zu einer längeren Tabelle zusammenfügen, um das Management der Daten zu vereinfachen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_of_output = \"combined_data\"\n",
    "'''\n",
    "This cell combines data (if wanted)\n",
    "and saves it under data/2-combined_data\n",
    "\n",
    "'''\n",
    "\n",
    "df1 = pd.read_pickle(\"data/1-download_cache/Ed_Sheeran-Thinking_Out_Loud-280373.pkl\")\n",
    "df2 = pd.read_pickle(\"data/1-download_cache/Bruno_Mars-When_I_Was_Your_Man_155312.pkl\")\n",
    "df3 = pd.read_pickle(\"data/1-download_cache/John_Legend-All_of_Me-187985.pkl\")\n",
    "df4 = pd.read_pickle(\"data/1-download_cache/Tom_Odell-Another_Love-90400.pkl\")\n",
    "\n",
    "data_combined = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "print(data_combined.shape)\n",
    "data_combined.to_pickle(\"data/2-combined_data/{}.pkl\".format(filename_of_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162d2dd",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "In den folgenden Zellen werden jene Kommentare gelöscht, die rein aus Zeichen, Emojies oder einer URL bestehen.\n",
    "\n",
    "Unter \"filename_of_output\" lässt sich definieren, unter welchem Namen die Daten nach erfolgreichen Prozess gespeichert werden sollen. Sie landen in jedem Fall im data/3-processed_data/cache/ Directory.\n",
    "\n",
    "Außerdem sollte unter load data der richtige Pfad zum Input-File angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print what is in download_cache\n",
    "print(*files_in_dir(\"data/1-download_cache/\"), sep=\"\\n\")\n",
    "print(20*\"-\")\n",
    "### print what is in data/2-combined_data\n",
    "print(*files_in_dir(\"data/2-combined_data/\"), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from my_functions import ident_lang\n",
    "\n",
    "#load data\n",
    "df_comments = pd.read_pickle(\"data/1-download_cache/Ed_Sheeran-Thinking_Out_Loud-576.pkl\") #CHANGE\n",
    "\n",
    "#output filename\n",
    "filename_of_output = \"processed_data\"\n",
    "\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "print(df_comments.shape)\n",
    "\n",
    "### Pre Process\n",
    "\n",
    "print(\"deleted extreamly long comments (which are probably lyrics)\")\n",
    "df_comments = df_comments[df_comments['comment'].str.len()<1100] #aprox 200 words\n",
    "print(df_comments.shape)\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "\n",
    "\n",
    "## deleted all comments without latin characters\n",
    "#find rows\n",
    "patternDel = fr\"\\A[^a-z]+\\Z\"\n",
    "i_filter = df_comments['comment'].str.contains(patternDel, regex=True, case=False)\n",
    "#keep all rows which indices do not match i_filter\n",
    "df_comments = df_comments[~i_filter]\n",
    "print(df_comments.shape)\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "print(\"deleted all comments without latin characters\")\n",
    "df_filtered_out = df_comments[i_filter]\n",
    "\n",
    "\n",
    "\n",
    "## deleted all comments which are only URL\n",
    "#find rows\n",
    "patternDel = fr\"\\Ahttp\\S*\\Z\"\n",
    "i_filter = df_comments['comment'].str.contains(patternDel, regex=True, case=False)\n",
    "#keep all rows which indices do not match i_filter\n",
    "df_comments = df_comments[~i_filter]\n",
    "print(df_comments.shape)\n",
    "print(\"deleted all comments which are only URL\")\n",
    "df_filtered_out_2 = df_comments[i_filter]\n",
    "\n",
    "\n",
    "# detect languages\n",
    "print(\"language detection - this can take some time:\")\n",
    "# to show progress\n",
    "ident_lang.index = 0\n",
    "ident_lang.length = df_comments.shape[0]\n",
    "df_comments = df_comments.reset_index(drop=True)\n",
    "## initiate detection\n",
    "df_comments[\"lang\"] = df_comments[\"comment\"].apply(lambda x: ident_lang(x))\n",
    "\n",
    "print(\"language detection is finished\")\n",
    "\n",
    "# save file\n",
    "df_comments.to_pickle(\"data/3-processed_data/cache/{}.pkl\".format(filename_of_output))\n",
    "print(f\"file saved as {filename_of_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa2b90",
   "metadata": {},
   "source": [
    "Mit der folgenden Zelle lassen sich alle Kommentare anzeigen, die zuvor herausgelöscht wurden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view filtered-out comments\n",
    "df_filtered = pd.concat([df_filtered_out, df_filtered_out_2])\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a50989",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11dd8b0",
   "metadata": {},
   "source": [
    "# Analyse der Time Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standart packages\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from langdetect import detect\n",
    "import tabloo\n",
    "from my_functions import files_in_dir, extract_ts, plot_time_stamp\n",
    "\n",
    "### print what is in processed cache folder\n",
    "files_in_dir(\"data/3-processed_data/cache/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2218bc",
   "metadata": {},
   "source": [
    "## Extraktion der Time Stamps\n",
    "Nun kann sich ein file ausgesucht werden, dessen time stamps extrahiert werden sollen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Config\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#load data\n",
    "df_comments = pd.read_pickle(\"data/3-processed_data/cache/processed_data.pkl\")\n",
    "\n",
    "#extract TSs\n",
    "df_comments['time_stamps'] = df_comments[\"comment\"].apply(lambda x: extract_ts(x))\n",
    "\n",
    "# print number of ts comments in dataframe\n",
    "print(\"Time Stamps wurden erfolgreich in der 'time stamp' Spalte abgespeichert\")\n",
    "\n",
    "df_comments.to_pickle(\"data/3-processed_data/cache/processed_data_ts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232964ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save csv of only comments with ts\n",
    "df_only_ts = df_comments[df_comments[\"time_stamps\"] != \"NA\"]\n",
    "print(df_only_ts)\n",
    "df_only_ts.to_csv(\"data/ts_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660dbcf3",
   "metadata": {},
   "source": [
    "## Grafische Darstellung der Time Stamps über den Verlauf des Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2cba0",
   "metadata": {},
   "source": [
    "In der folgenden Zelle lassen sich Input-File und Sprache der zu analysierenden time stamp Kommentare festlegen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71d12b",
   "metadata": {},
   "source": [
    "### Nun kann sich ein Video aus der nächsten Zelle ausgesucht werden und unten als origin_name eingegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d40bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df_comments = pd.read_pickle(\"data/3-processed_data/cache/processed_data_ts.pkl\")\n",
    "\n",
    "# filter by language (if wanted)\n",
    "#language = \"en\" # use two-character abbreveation\n",
    "#df_comments = df_comments[df_comments[\"lang\"] == language]\n",
    "\n",
    "# print what videos are in DataFrame\n",
    "print(\"origin_names:\")\n",
    "print(10*\"-\")\n",
    "print(*df_comments[\"origin\"].unique(), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Please use the plot_time_stamp(df, origin_name, max_min, save, schow_data) function to\n",
    "plot the distribution of time stamps.\n",
    "\n",
    "\"df\" defines the Pandas DataFrame to work with\n",
    "\"origin_name\" defines the the video by filtering the \"origin\" column\n",
    "\"max_min\" should be set to the video_length and sets the x-axis of the plot\n",
    "\"save\" should be set to True, to save the plot in the figures folder.\n",
    "The Name of the .png picture will be a mix of the origin_name and amount of\n",
    "time stamps found.\n",
    "\"show_data\" lets you see the distribution of time stamps as a list of dictionaries.\n",
    "'''\n",
    "\n",
    "from my_functions import plot_time_stamp \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plot ts\n",
    "plot_time_stamp(df = df_comments,\n",
    "                origin_name = \"Ed_Sheeran-Thinking_Out_Loud\",\n",
    "                max_min = \"5:00\",\n",
    "                save = True,\n",
    "                show_data = False,\n",
    "                show_data_not_rounded = False)\n",
    "\n",
    "#plot ts\n",
    "plot_time_stamp(df = df_comments,\n",
    "                origin_name = \"Bruno_Mars-When_I_Was_Your_Man\",\n",
    "                max_min = \"4:00\",\n",
    "                save = True,\n",
    "                show_data = False,\n",
    "                show_data_not_rounded = False)\n",
    "\n",
    "#plot ts\n",
    "plot_time_stamp(df = df_comments,\n",
    "                origin_name = \"John_Legend-All_of_Me\",\n",
    "                max_min = \"5:10\",\n",
    "                save = True,\n",
    "                show_data = False,\n",
    "                show_data_not_rounded = False)\n",
    "\n",
    "\n",
    "#plot ts\n",
    "plot_time_stamp(df = df_comments,\n",
    "                origin_name = \"Tom_Odell-Another_Love\",\n",
    "                max_min = \"4:10\",\n",
    "                save = True,\n",
    "                show_data = False,\n",
    "                show_data_not_rounded = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73a46c",
   "metadata": {},
   "source": [
    "# Analyse des Grads der Schnulzigkeit mit ML-Methoden\n",
    "Nun wird unser zuvor an 1000 Kommentaren trainiertes Modell der Erkennung von schnulzigen Kommentaren genutzt, um die Schnulzigkeit von normalen und Kommentaren mit time stamp zu vergleichen\n",
    "\n",
    "**Hierfür braucht man ein Model! Man kann ein bereits vortrainiertes benutzen, oder das classify_comments.py Skript im /bert Ordner benutzen, um eines zu trainieren!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3da7e8-b2f2-482a-bcdf-35099579f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print what is in processed cache folder\n",
    "print(*files_in_dir(\"data/3-processed_data/cache/\"), sep=\"\\n\")\n",
    "\n",
    "### print what is in models folder\n",
    "print(\"models:\")\n",
    "print(*files_in_dir(\"bert/models/\"), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3cd3da",
   "metadata": {},
   "source": [
    "### Vorhersage des Schnulzigkeitsgrads pro Kommentar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "# https://pypi.org/project/simpletransformers/ <- source evaluation tipps\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "from my_functions import apply_model_in_jupyter\n",
    "\n",
    "# specify model\n",
    "modelname = \"bert/models/final_model\"\n",
    "\n",
    "# import and specify data\n",
    "df_comments = pd.read_pickle(\"data/3-processed_data/cache/processed_data_ts.pkl\")\n",
    "# only english comments, because that is what the model is trained for\n",
    "df_comments = df_comments[df_comments[\"lang\"] == \"en\"]\n",
    "# split\n",
    "df_no = df_comments[df_comments[\"time_stamps\"] == \"NA\"]\n",
    "df_ts = df_comments[df_comments[\"time_stamps\"] != \"NA\"]\n",
    "# shuffle data and drop old index\n",
    "df_ts = df_ts.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_no = df_no.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "# only take 5000\n",
    "df_input_no = df_no.head(5000)\n",
    "df_input_ts = df_ts.head(5000)\n",
    "#convert to list\n",
    "apply_lst_no = df_input_no[\"comment\"].tolist()\n",
    "apply_lst_ts = df_input_ts[\"comment\"].tolist()\n",
    "\n",
    "\n",
    "# apply\n",
    "#df_output_no = apply_model_in_jupyter(apply_lst_no, modelname)\n",
    "df_output_ts = apply_model_in_jupyter(apply_lst_ts, modelname)\n",
    "\n",
    "\n",
    "# add metadata to prediction dfs\n",
    "df_output_no = pd.merge(df_no, df_input_no, left_index=True, right_index=True)\n",
    "df_output_ts = pd.merge(df_output_ts, df_input_ts, left_index=True, right_index=True)\n",
    "# combine both dfs to one\n",
    "df_combined = pd.concat([df_output_no, df_output_ts])\n",
    "# save\n",
    "df_combined.to_csv(\"data/predictions.csv\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5325874",
   "metadata": {},
   "source": [
    "## Analyse des Schnulzigkeitsgrads: Kommentare mit vs. Kommentare ohne TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from my_functions import grad_der_schnulzigkeit\n",
    "\n",
    "df_predictions = pd.read_csv(\"data/predictions.csv\", sep=\",\")\n",
    "# print what videos are in DataFrame\n",
    "print(\"origin_names:\")\n",
    "print(*df_predictions[\"origin\"].unique(), sep=\"\\n\")\n",
    "\n",
    "df1 = grad_der_schnulzigkeit(df_predictions, \"Bruno_Mars-When_I_Was_Your_Man\")\n",
    "df2 = grad_der_schnulzigkeit(df_predictions, \"Ed_Sheeran-Thinking_Out_Loud\")\n",
    "df3 = grad_der_schnulzigkeit(df_predictions, \"John_Legend-All_of_Me\")\n",
    "df4 = grad_der_schnulzigkeit(df_predictions, \"Tom_Odell-Another_Love\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008310a6-ba93-4d1f-baa1-1038eb40c48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
